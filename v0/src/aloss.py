'''
Implementation of Optimal Subset Selection for Active Learning
'''
import numpy as np
import copy
import functools
import time
import random
from scipy.spatial.distance import cdist

# problem statement: given some n x n matrix M and some limit k,
# return a vector (n x 1) of at most k 1's and n - k 0's such that
# e^T M e is maximum
# currently does not work efficiently :(
def solver(M, n, i, j, e):
    if j == k:
        ve = np.array(e)
        vi = np.matmul(np.matmul(ve.transpose(), M), ve)
        return (vi, copy.deepcopy(e))

    # we have reached our limit, and j hasn't been filled up
    if i >= n:
        return (None, None)

    tempE = copy.deepcopy(e)
    tempE[i] = 1
    # second call, we add our current elem into vector set.
    (m2, e2) = solver(M, n, i + 1, j + 1, copy.deepcopy(tempE))
    # first call, we do not add our current elem into vector set.
    (m1, e1) = solver(M, n, i + 1, j, copy.deepcopy(e))

    if m1 == None and m2 == None:
        return (None, None)

    ve = np.array(e2)
    vi = np.matmul(np.matmul(ve.transpose(), M), ve)
    if m2 == None or (m1 != None and m1 > m2 + vi):
        return (m1, e1)
    return (m2 + vi, e2)

def approx_solver(M, k):
    n = len(M)
    best = 0
    best_vec = None
    iters = n ** 2
    for _ in range(iters):
        e = [0 for _ in range(n)]
        i = 0
        numbers = set()
        while i < k:
            num = random.randint(0, n-1)
            if num not in numbers:
                numbers.add(num)
                i += 1
        for num in numbers:
            e[num] = 1
        score = compute_wei(e, M)
        if score > best:
            best_vec = e
            best = score
    return best_vec

def find_max_e(M, k):
    n = len(M)
    memo = [[None for _ in range(k + 1)] for _ in range(n + 1) ]
    e = [0 for _ in range(n)]
    # i = current elem we are on
    # j = current # of elems we've added
    # e = current vector we are modifying
    (best, e) = solver(M, n, 0, 0, e)
    return e

#just to make sure our thing is good, we run brute force sol
def brute_force_solver(M, k):
    # given input x, generate all arrays with x 1's of length n
    def get_vectors(x, n):
        if x == 0: return [[0 for _ in range(n)]]
        if n == 0: return None
        res = []
        #res1 will return all arrays with x 1's of length n - 1.
        #we append 0's to these puppies
        res1 = get_vectors(x, n-1)
        #res2 will return all arrays with x-1 1's of length n - 1.
        #we append 1's to these kitties
        res2 = get_vectors(x-1, n-1)
        if res1 == None and res2 == None:
            return None
        if res1 != None:
            for arr in res1:
                res.append(arr + [0])
        if res2 != None:
            for arr in res2:
                res.append(arr + [1])
        return res
        # for arr in get_vectors(x-1, n-1):
            # res.append(arr)
    vectors = get_vectors(k, len(M))
    maxIndex = None
    maxVal = 0
    for i, e in enumerate(vectors):
        ve = np.array(e)
        vi = np.matmul(np.matmul(ve.transpose(), M), ve)
        if vi > maxVal:
            maxIndex = i
            maxVal = vi
    return vectors[maxIndex]

# M = [
#     [9,0,0,0,0],
#     [0,0,0,0,0],
#     [0,0,9,0,0],
#     [0,0,0,8,0],
#     [0,0,0,0,0],
# ]

# size = 20
# M = np.random.rand(size, size)
#
def compute_wei(e, M):
    ve = np.array(e)
    return np.matmul(np.matmul(ve.transpose(), M), ve)
#
# k = 5

# now = time.time()
# wei2 = find_max_e(M, k)
# wei2 = approx_solver(M, k)
# print("my sol took", time.time() - now)
# now = time.time()
# wei1 = brute_force_solver(M, k)
# print("brute force took", time.time() - now)
# print("actual sol\t", compute_wei(wei1, M), wei1)
# print("my sol\t\t", compute_wei(wei2, M), wei2)
# a = np.array([1,0,1,0,0])
# b = np.matmul(a.transpose(), M)
# d = np.matmul(b, a)
# print(d)

def instance_disparities(d):
    return cdist(d, d, 'euclidean')
    # n = len(d)
    # print("wei-1", n, d)
    # return
    # #m1 has repeated columns
    # m1 = np.tile(d, (n,1))
    # print("wei0")
    # #m2 has repeated rows
    # m2 = np.tile(np.array([d]).transpose(), (1,n))
    # print("wei1")
    # diffs = m1 - m2
    # print("wei2")
    # disparity = diffs * diffs
    # print("wei3")
    # return disparity / np.max(disparity)



# returns euclidean distance between the two feature vectors
def instance_disparity(f1, f2):
    diffs = f1 - f2
    diffs *= diffs
    return sum(diffs)

# returns all uncertainties generated by our classifier
def instance_uncertainties(clf, features):
    probs = np.min(clf.predict_proba(features), axis=1)
    # probs = min(clf.predict_proba([f])[0])
    return probs

vec1 = [1,2,3]
vec2 = [1,2,13]

print(instance_disparity(np.array(vec1), np.array(vec2)))
